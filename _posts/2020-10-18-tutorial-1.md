---
title: "tutorial"
layout: post
theme: 
 
categories: Jupyter_Notebooks
---

### Naive Bayes classifier and its Math

How do we understand $E=EF \cup E \overline{F}$?  

Let us consider an example. In a population, lets say people can be divided into two classes: those who are accident prone and those who are not. Now we are interested to find the probability of an accident. It is easy to see that an accident can happen in both accident prone and not prone group of people. Therefore, accidents indicated by set $E$ is equivalent to $E=EF \cup E \overline{F}$ where set $F$ and $\overline{F}$ indicates the set of accident prone and not prone group of people. To compute the probability of accident we simply this $ P(EF \cup E \overline{F})$ 

Another example from Wikipedia, Suppose that two factories supply light bulbs to the market. Factory X's bulbs work for over 5000 hours in 99% of cases, whereas factory Y's bulbs work for over 5000 hours in 95% of cases. It is known that factory X supplies 60% of the total bulbs available and Y supplies 40% of the total bulbs available. What is the chance that a purchased bulb will work for longer than 5000 hours?

Generalising the above concept.

$E=EF_1 \cup EF_2 \cup EF_3  \cup ..... EF_n$. Lets say we have a population for example insects (may be a type of butterfly) this population can be divided in terms of the continent to which they are endemic to and think of $F_i$'s as these subdivided population and now let $E$'s to be a sudden genetic mutation in this population. Now we can easily compute the probability of a sudden gentic mutation in this population. Here in this situation 'n' is 6. 

Make sure that you notice from the generalisation that all we are doing is mutually exclusively breaking our sample space into finite chunks and then we focus on each chunks and compute the required probability. Then we assemble them back by adding it together.

### Law of Total Probability  

The law of total probability is the proposition that if $\{B_n : n = 1,2,3,..\}$ is a finite partition of a sample space (in other words, a set of pairwise disjoint events whose union is the entire sample space) then for any event A {\displaystyle A} A of the same probability space: $P(A)=P(A \\ B_n)$





```python

```
